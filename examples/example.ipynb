{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trendmaster import TrendMaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/SBIN_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#Initialize the TrendMaster object\n",
    "tm = TrendMaster(symbol_name_stk='SBIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your Zerodha credentials:\n",
      "Fetching data for SBIN\n",
      "Data saved to SBIN_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Load your data\n",
    "test_symbol = 'SBIN'\n",
    "data = tm.load_data(symbol=test_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          date    open    high     low   close  volume\n",
      "0    2024-05-02 09:15:00+05:30  826.90  831.00  825.00  830.05  327171\n",
      "1    2024-05-02 09:16:00+05:30  830.45  831.20  829.50  830.65  220040\n",
      "2    2024-05-02 09:17:00+05:30  830.60  833.00  830.40  832.65  191248\n",
      "3    2024-05-02 09:18:00+05:30  832.85  833.40  831.10  832.65  282668\n",
      "4    2024-05-02 09:19:00+05:30  832.85  833.00  831.50  832.00  153414\n",
      "...                        ...     ...     ...     ...     ...     ...\n",
      "2620 2024-05-10 15:25:00+05:30  817.10  817.55  816.80  817.40   47022\n",
      "2621 2024-05-10 15:26:00+05:30  817.30  817.45  816.55  816.95   87103\n",
      "2622 2024-05-10 15:27:00+05:30  817.15  817.15  816.25  816.45   49659\n",
      "2623 2024-05-10 15:28:00+05:30  816.65  817.10  816.25  816.70   32065\n",
      "2624 2024-05-10 15:29:00+05:30  816.50  817.15  816.20  816.85   65348\n",
      "\n",
      "[2625 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\trendmaster\\trainer.py:111: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  inputs = torch.FloatTensor([item[0] for item in batch]).to(self.device)\n",
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([1, 10])) that is different to the input size (torch.Size([1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/ 2425 batches | lr 0.000001 | 34.04 ms | loss 28.42016 | ppl 2201500551498.64\n",
      "| epoch   1 |   200/ 2425 batches | lr 0.000001 | 37.88 ms | loss 27.48427 | ppl 863512891626.25\n",
      "| epoch   1 |   300/ 2425 batches | lr 0.000001 | 31.47 ms | loss 16.79133 | ppl 19605643.05\n",
      "| epoch   1 |   400/ 2425 batches | lr 0.000001 | 31.75 ms | loss 2.42401 | ppl    11.29\n",
      "| epoch   1 |   500/ 2425 batches | lr 0.000001 | 35.81 ms | loss 4.50919 | ppl    90.85\n",
      "| epoch   1 |   600/ 2425 batches | lr 0.000001 | 31.02 ms | loss 52.29151 | ppl 51275971459472947150848.00\n",
      "| epoch   1 |   700/ 2425 batches | lr 0.000001 | 31.18 ms | loss 44.59446 | ppl 23287759048583860224.00\n",
      "| epoch   1 |   800/ 2425 batches | lr 0.000001 | 30.21 ms | loss 1.99442 | ppl     7.35\n",
      "| epoch   1 |   900/ 2425 batches | lr 0.000001 | 34.87 ms | loss 0.99142 | ppl     2.70\n",
      "| epoch   1 |  1000/ 2425 batches | lr 0.000001 | 31.98 ms | loss 4.26460 | ppl    71.14\n",
      "| epoch   1 |  1100/ 2425 batches | lr 0.000001 | 31.67 ms | loss 42.18362 | ppl 2089848714934452480.00\n",
      "| epoch   1 |  1200/ 2425 batches | lr 0.000001 | 36.95 ms | loss 30.01062 | ppl 10800592971091.07\n",
      "| epoch   1 |  1300/ 2425 batches | lr 0.000001 | 32.27 ms | loss 7.96660 | ppl  2883.03\n",
      "| epoch   1 |  1400/ 2425 batches | lr 0.000001 | 31.94 ms | loss 2.51443 | ppl    12.36\n",
      "| epoch   1 |  1500/ 2425 batches | lr 0.000001 | 31.70 ms | loss 6.14128 | ppl   464.65\n",
      "| epoch   1 |  1600/ 2425 batches | lr 0.000001 | 35.89 ms | loss 12.71198 | ppl 331697.28\n",
      "| epoch   1 |  1700/ 2425 batches | lr 0.000001 | 36.29 ms | loss 9.38306 | ppl 11885.27\n",
      "| epoch   1 |  1800/ 2425 batches | lr 0.000001 | 32.61 ms | loss 2.67167 | ppl    14.46\n",
      "| epoch   1 |  1900/ 2425 batches | lr 0.000001 | 30.92 ms | loss 6.04993 | ppl   424.08\n",
      "| epoch   1 |  2000/ 2425 batches | lr 0.000001 | 32.00 ms | loss 53.79560 | ppl 230744611081473279131648.00\n",
      "| epoch   1 |  2100/ 2425 batches | lr 0.000001 | 30.12 ms | loss 6.98467 | ppl  1079.95\n",
      "| epoch   1 |  2200/ 2425 batches | lr 0.000001 | 31.83 ms | loss 2.47668 | ppl    11.90\n",
      "| epoch   1 |  2300/ 2425 batches | lr 0.000001 | 35.42 ms | loss 2.59819 | ppl    13.44\n",
      "| epoch   1 |  2400/ 2425 batches | lr 0.000001 | 31.30 ms | loss 3.28963 | ppl    26.83\n"
     ]
    }
   ],
   "source": [
    "# #Train the model\n",
    "tm.train(test_symbol, transformer_params={'epochs': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_future() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Perform inference\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minferencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSBIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "\u001b[1;31mTypeError\u001b[0m: predict_future() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "#Perform inference\n",
    "predictions = tm.inferencer.predict_future(val_data=data,future_steps=100,symbol='SBIN')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrendmaster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minferencer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Inferencer\n\u001b[0;32m      4\u001b[0m inferencer \u001b[38;5;241m=\u001b[39m Inferencer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/SBIN_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, kite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43minferencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSBIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\trendmaster\\inferencer.py:63\u001b[0m, in \u001b[0;36mInferencer.predict_future\u001b[1;34m(self, val_data, future_steps, symbol)\u001b[0m\n\u001b[0;32m     61\u001b[0m truth \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     62\u001b[0m val_data \u001b[38;5;241m=\u001b[39m val_data\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Convert pandas DataFrame to numpy array\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m _ , data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, future_steps,\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\trendmaster\\inferencer.py:121\u001b[0m, in \u001b[0;36mInferencer.get_batch\u001b[1;34m(self, source, i, batch_size)\u001b[0m\n\u001b[0;32m    119\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(batch_size, \u001b[38;5;28mlen\u001b[39m(source) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    120\u001b[0m batch \u001b[38;5;241m=\u001b[39m source[i:i\u001b[38;5;241m+\u001b[39mseq_len]\n\u001b[1;32m--> 121\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not Timestamp"
     ]
    }
   ],
   "source": [
    "from trendmaster.inferencer import Inferencer\n",
    "\n",
    "\n",
    "inferencer = Inferencer('./models/SBIN_model.pkl', kite=None)\n",
    "predictions = inferencer.predict_future(data, future_steps=10, symbol='SBIN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m71"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
