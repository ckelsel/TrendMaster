{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trendmaster import TrendMaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/SBIN_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#Initialize the TrendMaster object\n",
    "tm = TrendMaster(symbol_name_stk='SBIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your Zerodha credentials:\n",
      "Fetching data for SBIN\n",
      "Data saved to SBIN_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Load your data\n",
    "test_symbol = 'SBIN'\n",
    "data = tm.load_data(symbol=test_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          date    open    high     low   close  volume\n",
      "0    2024-05-02 09:15:00+05:30  826.90  831.00  825.00  830.05  327171\n",
      "1    2024-05-02 09:16:00+05:30  830.45  831.20  829.50  830.65  220040\n",
      "2    2024-05-02 09:17:00+05:30  830.60  833.00  830.40  832.65  191248\n",
      "3    2024-05-02 09:18:00+05:30  832.85  833.40  831.10  832.65  282668\n",
      "4    2024-05-02 09:19:00+05:30  832.85  833.00  831.50  832.00  153414\n",
      "...                        ...     ...     ...     ...     ...     ...\n",
      "2620 2024-05-10 15:25:00+05:30  817.10  817.55  816.80  817.40   47022\n",
      "2621 2024-05-10 15:26:00+05:30  817.30  817.45  816.55  816.95   87103\n",
      "2622 2024-05-10 15:27:00+05:30  817.15  817.15  816.25  816.45   49659\n",
      "2623 2024-05-10 15:28:00+05:30  816.65  817.10  816.25  816.70   32065\n",
      "2624 2024-05-10 15:29:00+05:30  816.50  817.15  816.20  816.85   65348\n",
      "\n",
      "[2625 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\trendmaster\\trainer.py:111: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  inputs = torch.FloatTensor([item[0] for item in batch]).to(self.device)\n",
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([1, 10])) that is different to the input size (torch.Size([1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/ 2425 batches | lr 0.000001 | 33.25 ms | loss 85.93818 | ppl 21012529671469285338037947109145051136.00\n",
      "| epoch   1 |   200/ 2425 batches | lr 0.000001 | 34.48 ms | loss 79.05340 | ppl 21500878653947704947460846699675648.00\n",
      "| epoch   1 |   300/ 2425 batches | lr 0.000001 | 30.11 ms | loss 57.26056 | ppl 7378087694598164585644032.00\n",
      "| epoch   1 |   400/ 2425 batches | lr 0.000001 | 32.50 ms | loss 7.85224 | ppl  2571.49\n",
      "| epoch   1 |   500/ 2425 batches | lr 0.000001 | 30.85 ms | loss 17.58041 | ppl 43159535.77\n",
      "| epoch   1 |   600/ 2425 batches | lr 0.000001 | 29.69 ms | loss 49.18059 | ppl 2284862028840607154176.00\n",
      "| epoch   1 |   700/ 2425 batches | lr 0.000001 | 35.00 ms | loss 64.30408 | ppl 8450941249314608014900068352.00\n",
      "| epoch   1 |   800/ 2425 batches | lr 0.000001 | 29.52 ms | loss 17.45296 | ppl 37994820.30\n",
      "| epoch   1 |   900/ 2425 batches | lr 0.000001 | 30.86 ms | loss 9.96337 | ppl 21234.34\n",
      "| epoch   1 |  1000/ 2425 batches | lr 0.000001 | 30.33 ms | loss 6.68095 | ppl   797.08\n",
      "| epoch   1 |  1100/ 2425 batches | lr 0.000001 | 29.80 ms | loss 76.66705 | ppl 1977309318356556931923982092861440.00\n",
      "| epoch   1 |  1200/ 2425 batches | lr 0.000001 | 30.73 ms | loss 55.55959 | ppl 1346549031319642426048512.00\n",
      "| epoch   1 |  1300/ 2425 batches | lr 0.000001 | 34.24 ms | loss 15.73517 | ppl 6818646.35\n",
      "| epoch   1 |  1400/ 2425 batches | lr 0.000001 | 31.29 ms | loss 2.80549 | ppl    16.54\n",
      "| epoch   1 |  1500/ 2425 batches | lr 0.000001 | 31.47 ms | loss 4.61758 | ppl   101.25\n",
      "| epoch   1 |  1600/ 2425 batches | lr 0.000001 | 30.07 ms | loss 17.29784 | ppl 32535318.04\n",
      "| epoch   1 |  1700/ 2425 batches | lr 0.000001 | 32.03 ms | loss 4.81263 | ppl   123.06\n",
      "| epoch   1 |  1800/ 2425 batches | lr 0.000001 | 31.33 ms | loss 3.37098 | ppl    29.11\n",
      "| epoch   1 |  1900/ 2425 batches | lr 0.000001 | 32.92 ms | loss 4.62711 | ppl   102.22\n",
      "| epoch   1 |  2000/ 2425 batches | lr 0.000001 | 29.95 ms | loss 63.15213 | ppl 2670677042449227309505314816.00\n",
      "| epoch   1 |  2100/ 2425 batches | lr 0.000001 | 31.34 ms | loss 19.06731 | ppl 190908925.16\n",
      "| epoch   1 |  2200/ 2425 batches | lr 0.000001 | 32.46 ms | loss 7.35343 | ppl  1561.54\n",
      "| epoch   1 |  2300/ 2425 batches | lr 0.000001 | 31.90 ms | loss 2.26775 | ppl     9.66\n",
      "| epoch   1 |  2400/ 2425 batches | lr 0.000001 | 33.42 ms | loss 2.16332 | ppl     8.70\n"
     ]
    }
   ],
   "source": [
    "# #Train the model\n",
    "tm.train(test_symbol, transformer_params={'epochs': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_future() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Perform inference\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minferencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSBIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "\u001b[1;31mTypeError\u001b[0m: predict_future() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "#Perform inference\n",
    "predictions = tm.inferencer.predict_future(val_data=data,future_steps=100,symbol='SBIN')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrendmaster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minferencer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Inferencer\n\u001b[0;32m      4\u001b[0m inferencer \u001b[38;5;241m=\u001b[39m Inferencer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/SBIN_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, kite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43minferencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSBIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\trendmaster\\inferencer.py:62\u001b[0m, in \u001b[0;36mInferencer.predict_future\u001b[1;34m(self, val_data, future_steps, symbol)\u001b[0m\n\u001b[0;32m     60\u001b[0m test_result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;241m0\u001b[39m)    \n\u001b[0;32m     61\u001b[0m truth \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m _ , data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, future_steps,\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\trendmaster\\inferencer.py:121\u001b[0m, in \u001b[0;36mInferencer.get_batch\u001b[1;34m(self, source, i, batch_size)\u001b[0m\n\u001b[0;32m    119\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(batch_size, \u001b[38;5;28mlen\u001b[39m(source) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    120\u001b[0m batch \u001b[38;5;241m=\u001b[39m source[i:i\u001b[38;5;241m+\u001b[39mseq_len]\n\u001b[1;32m--> 121\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "from trendmaster.inferencer import Inferencer\n",
    "\n",
    "\n",
    "inferencer = Inferencer('./models/SBIN_model.pkl', kite=None)\n",
    "predictions = inferencer.predict_future(data, future_steps=10, symbol='SBIN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m71"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
